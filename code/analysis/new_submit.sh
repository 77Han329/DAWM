#!/usr/bin/env bash
#SBATCH --job-name=train_dawm
#SBATCH --output=slurmlogs/train/%x_%j.out 
#SBATCH --partition=lrz-hgx-h100-94x4
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=4
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --time=2-00:00:00  # 2 å¤©
# ===== ç¯å¢ƒå‡†å¤‡ =====
source ~/.bashrc
conda activate dawm

export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia
export PYTHONPATH=$PYTHONPATH:/dss/dsshome1/0C/di97zuq/project/DAWM/code

cd /dss/dsshome1/0C/di97zuq/project/DAWM/code/analysis || { echo "âŒ cd failed"; exit 1; }

# ===== å‚æ•°æ¥æ”¶ =====
ENV=$1
HORIZON=$2
RETURNSCALE=$3
BATCH_SIZE=$4
LEARNING_RATE=$5
N_TRAIN_STEPS=$6
CONFIG_FILE="new_temp_config_${ENV}_${HORIZON}_${RETURNSCALE}.jsonl"

# å›ºå®šå‚æ•°

# ===== æ£€æŸ¥ GPU çŠ¶æ€ =====
echo "ğŸ” Checking GPU availability..."
python - <<EOF
import torch
if torch.cuda.is_available():
    print(f"âœ… CUDA device: {torch.cuda.get_device_name(0)}")
else:
    print("âŒ torch.cuda.is_available() == False â€” CUDA device not available")
EOF

# ===== è°ƒè¯•è¾“å‡º =====
echo "ğŸ“‚ å½“å‰ç›®å½•: $(pwd)"
echo "ğŸ” æŸ¥æ‰¾ new_train.jsonl..."
ls -l new_train.jsonl || { echo "âŒ æ‰¾ä¸åˆ° new_train.jsonl"; exit 1; }

# ===== ç”Ÿæˆ JSONL æ–‡ä»¶ =====
python <<EOF
import json, os

env_new = "$ENV"
horizon_new = int($HORIZON)
return_scale_new = float($RETURNSCALE)
batch_size_new = $BATCH_SIZE
learning_rate_new = $LEARNING_RATE
n_train_steps_new = $N_TRAIN_STEPS

with open("new_train.jsonl", "r") as f:
    lines = f.readlines()

new_lines = []
for line in lines:
    config = json.loads(line)
    env_old = config.get("env", "")
    horizon_old = config.get("horizon", "")
    seed = config.get("seed", 100)

    # æ›´æ–°è®­ç»ƒå‚æ•°
    config["env"] = env_new
    config["dataset"] = env_new
    config["horizon"] = horizon_new
    config["returns_scale"] = return_scale_new
    config["batch_size"] = batch_size_new
    config["learning_rate"] = learning_rate_new
    config["n_train_steps"] = n_train_steps_new

    # æ„é€ è·¯å¾„
    subdir = f"horizon_{horizon_new}/batch_{batch_size_new}/lr_{learning_rate_new}/steps_{n_train_steps_new}/{env_new}/{seed}"
    config["RUN.prefix"] = f"diffuser/default_inv/{subdir}"
    config["RUN.job_name"] = subdir
    config["bucket"] = f"/dss/dsshome1/0C/di97zuq/project/DAWM/weights/{subdir}"

    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰
    os.makedirs(config["bucket"], exist_ok=True)

    new_lines.append(json.dumps(config))

with open("$CONFIG_FILE", "w") as f:
    for line in new_lines:
        f.write(line + "\\n")
EOF

# ===== æ£€æŸ¥æ˜¯å¦å†™æˆåŠŸ =====
if [[ ! -f "$CONFIG_FILE" ]]; then
    echo "âŒ Failed to generate config file: $CONFIG_FILE"
    exit 1
fi

echo "âœ… Using config file: $CONFIG_FILE"

# ===== å¯åŠ¨è®­ç»ƒ =====
python train.py "$CONFIG_FILE"